{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Environment and Dependencies\n",
    "\n",
    "1. Subir un archivo con nombre env que tenga la clave de OpenAI\n",
    "2. Renombrarlo a .env\n",
    "3. Subir usina.db para que esten los datos disponibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.12.9)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/facunesh/Projects/hackaton-usina/data-organigrama/.venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain_community langchain_openai typing_extensions python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "from langchain import hub\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_community.tools.sql_database.tool import QuerySQLDatabaseTool\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Database and LLM\n",
    "Initialize the LLM model and connect to the SQLite database containing organizational data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LLM model\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "\n",
    "# Connect to the SQLite database\n",
    "db = SQLDatabase.from_uri(\"sqlite:///usina.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Data Structures\n",
    "Define the State and QueryOutput TypedDict classes for managing data flow through the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the State TypedDict for managing data flow through the application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    query: str\n",
    "    result: str\n",
    "    answer: str\n",
    "\n",
    "# Define the QueryOutput TypedDict for the generated SQL query\n",
    "class QueryOutput(TypedDict):\n",
    "    \"\"\"Generated SQL query.\"\"\"\n",
    "    query: Annotated[str, ..., \"Syntactically valid SQL query.\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Query Generation\n",
    "Implement the write_query function to generate SQL queries from natural language questions using LangChain prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the write_query function to generate SQL queries from natural language questions using LangChain prompts\n",
    "def write_query(state: State):\n",
    "    \"\"\"Generate SQL query to fetch information.\"\"\"\n",
    "    query_prompt_template = hub.pull(\"langchain-ai/sql-query-system-prompt\")\n",
    "\n",
    "    prompt = query_prompt_template.invoke(\n",
    "        {\n",
    "            \"dialect\": db.dialect,\n",
    "            \"top_k\": 10,\n",
    "            \"table_info\": db.get_table_info(),\n",
    "            \"input\": state[\"question\"],\n",
    "        }\n",
    "    )\n",
    "    structured_llm = llm.with_structured_output(QueryOutput)\n",
    "    result = structured_llm.invoke(prompt)\n",
    "    return result[\"query\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute SQL Queries\n",
    "Implement the execute_query function that uses QuerySQLDatabaseTool to run SQL queries against the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the execute_query function to run SQL queries against the database using QuerySQLDatabaseTool\n",
    "def execute_query(state: State):\n",
    "    \"\"\"Execute SQL query.\"\"\"\n",
    "    execute_query_tool = QuerySQLDatabaseTool(db=db)\n",
    "    return execute_query_tool.invoke(state[\"query\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Natural Language Answers\n",
    "Implement the generate_answer function to transform SQL results into human-readable answers using the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the generate_answer function to transform SQL results into human-readable answers using the LLM\n",
    "def generate_answer(state: State):\n",
    "    \"\"\"Answer question using retrieved information as context.\"\"\"\n",
    "    prompt = (\n",
    "        \"Given the following user question, corresponding SQL query, \"\n",
    "        \"and SQL result, answer the user question.\\n\\n\"\n",
    "        f'Question: {state[\"question\"]}\\n'\n",
    "        f'SQL Query: {state[\"query\"]}\\n'\n",
    "        f'SQL Result: {state[\"result\"]}'\n",
    "    )\n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Application\n",
    "Create an interactive interface to accept user questions and display answers with intermediate SQL queries and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Application\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Create input widget for user question\n",
    "question_input = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Type your question here',\n",
    "    description='Question:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Create output widgets for displaying intermediate SQL query, results, and final answer\n",
    "query_output = widgets.Output()\n",
    "result_output = widgets.Output()\n",
    "answer_output = widgets.Output()\n",
    "\n",
    "# Function to handle user input and display results\n",
    "def on_submit(change):\n",
    "    state = State()\n",
    "    state[\"question\"] = question_input.value\n",
    "    state[\"query\"] = write_query(state)\n",
    "    \n",
    "    with query_output:\n",
    "        query_output.clear_output()\n",
    "        print(f\"Generated SQL Query: {state['query']}\")\n",
    "    \n",
    "    state[\"result\"] = execute_query(state)\n",
    "    \n",
    "    with result_output:\n",
    "        result_output.clear_output()\n",
    "        print(f\"SQL Query Result: {state['result']}\")\n",
    "    \n",
    "    state[\"answer\"] = generate_answer(state)\n",
    "    \n",
    "    with answer_output:\n",
    "        answer_output.clear_output()\n",
    "        print(f\"Answer: {state['answer']}\")\n",
    "\n",
    "# Link the function to the input widget\n",
    "question_input.on_submit(on_submit)\n",
    "\n",
    "# Display the widgets\n",
    "display(question_input, query_output, result_output, answer_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
