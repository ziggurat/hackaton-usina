{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # pip install pymupdf\n",
    "\n",
    "import numpy as np\n",
    "from shapely.geometry import box\n",
    "import pandas as pd\n",
    "\n",
    "import io\n",
    "\n",
    "from shapely.geometry import box\n",
    "from shapely.ops import unary_union\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import pytesseract\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from chromadb.utils.embedding_functions import OpenCLIPEmbeddingFunction\n",
    "\n",
    "from chromadb.utils.data_loaders import ImageLoader\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_experimental.open_clip import OpenCLIPEmbeddings\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IngestionPipeline:\n",
    "    \n",
    "    def __init__(self, dir_path: str, create=True):\n",
    "        self.dir_path = dir_path\n",
    "        \n",
    "        # set default text and image embedding functions\n",
    "        self.embedding_function = OpenCLIPEmbeddingFunction()\n",
    "        self.chroma_collection = self.create_vector_store(create=create)\n",
    "\n",
    "    \n",
    "    def create_vector_store(self, create=True, db_dir='chromadb/'):\n",
    "\n",
    "        db_name = self.dir_path + db_dir\n",
    "        if not os.path.exists(db_name):\n",
    "            print(\"Creating vector store: \", db_name)\n",
    "            os.mkdir(db_name)\n",
    "        else:\n",
    "            print(\"Updating vector store:\", db_name)\n",
    "\n",
    "        # create client and a new collection\n",
    "        self.chroma_client = chromadb.PersistentClient(path=db_name, settings=Settings(allow_reset=True))\n",
    "        image_loader = ImageLoader()\n",
    "\n",
    "        if create:\n",
    "            print(\"Deleting existing collection ...\")\n",
    "            self.chroma_client.reset()\n",
    "            print(\"Creating new collection ...\")\n",
    "            chroma_collection = self.chroma_client.get_or_create_collection(\n",
    "                \"multimodal_collection\", metadata={\"hnsw:space\": \"cosine\"},\n",
    "                embedding_function=self.embedding_function,\n",
    "                data_loader=image_loader\n",
    "            )\n",
    "        else:\n",
    "            print(\"Recovering existing collection ...\")\n",
    "            chroma_collection = self.chroma_client.get_or_create_collection(\n",
    "                \"multimodal_collection\", metadata={\"hnsw:space\": \"cosine\"},\n",
    "                embedding_function=self.embedding_function,\n",
    "                data_loader=image_loader\n",
    "            )\n",
    "            print(\"elements:\", chroma_collection.count())\n",
    "\n",
    "        return chroma_collection\n",
    "\n",
    "    @staticmethod\n",
    "    def are_rectangles_connected(rect1, rect2, threshold=0):\n",
    "        \"\"\"\n",
    "        Check if two rectangles are connected (overlap or close within a threshold).\n",
    "        \n",
    "        :param rect1: Tuple (x1, y1, x2, y2) for the first rectangle.\n",
    "        :param rect2: Tuple (x1, y1, x2, y2) for the second rectangle.\n",
    "        :param threshold: Minimum distance to consider rectangles as connected.\n",
    "        :return: True if connected, False otherwise.\n",
    "        \"\"\"\n",
    "        b1 = box(*rect1).buffer(threshold)  # Expand rect1 by threshold\n",
    "        b2 = box(*rect2)\n",
    "        return b1.intersects(b2)\n",
    "\n",
    "    @staticmethod\n",
    "    def group_connected_rectangles(rectangles, threshold=0):\n",
    "        \"\"\"\n",
    "        Group rectangles into clusters based on connectivity.\n",
    "        \n",
    "        :param rectangles: List of rectangles [(x1, y1, x2, y2), ...]\n",
    "        :param threshold: Distance threshold to consider rectangles connected.\n",
    "        :return: List of grouped rectangles as [(grouped_x1, grouped_y1, grouped_x2, grouped_y2), ...]\n",
    "        \"\"\"\n",
    "        n = len(rectangles)\n",
    "        adjacency_matrix = np.zeros((n, n), dtype=bool)\n",
    "        \n",
    "        # Build adjacency matrix\n",
    "        for i in range(n):\n",
    "            for j in range(i + 1, n):\n",
    "                if IngestionPipeline.are_rectangles_connected(rectangles[i], rectangles[j], threshold):\n",
    "                    adjacency_matrix[i, j] = True\n",
    "                    adjacency_matrix[j, i] = True\n",
    "        \n",
    "        # Find connected components\n",
    "        visited = [False] * n\n",
    "        groups = []\n",
    "        \n",
    "        def dfs(node, group):\n",
    "            visited[node] = True\n",
    "            group.append(node)\n",
    "            for neighbor in range(n):\n",
    "                if adjacency_matrix[node, neighbor] and not visited[neighbor]:\n",
    "                    dfs(neighbor, group)\n",
    "        \n",
    "        for i in range(n):\n",
    "            if not visited[i]:\n",
    "                group = []\n",
    "                dfs(i, group)\n",
    "                groups.append(group)\n",
    "        \n",
    "        # Merge rectangles within each group\n",
    "        grouped_rectangles = []\n",
    "        for group in groups:\n",
    "            x_min = min(rectangles[i][0] for i in group)\n",
    "            y_min = min(rectangles[i][1] for i in group)\n",
    "            x_max = max(rectangles[i][2] for i in group)\n",
    "            y_max = max(rectangles[i][3] for i in group)\n",
    "            grouped_rectangles.append((x_min, y_min, x_max, y_max))\n",
    "        \n",
    "        return grouped_rectangles\n",
    "    \n",
    "    @staticmethod\n",
    "    def stitch_grouped_images_with_dpi(image_data, image_coords, grouped_boxes, dpi=300):\n",
    "        \"\"\"\n",
    "        Stitch images together for each grouped bounding box, preserving size and quality.\n",
    "        \n",
    "        :param image_data: List of image bytes.\n",
    "        :param image_coords: List of tuples [(x1, y1, x2, y2)], coordinates of the images in the PDF.\n",
    "        :param grouped_boxes: List of grouped bounding boxes [(group_x1, group_y1, group_x2, group_y2)].\n",
    "        :param dpi: DPI value to scale the images correctly.\n",
    "        :return: List of stitched PIL.Image objects, one for each group.\n",
    "        \"\"\"\n",
    "        # Scale factor to convert coordinates to pixels\n",
    "        scale = dpi / 72  # 72 is the default DPI in PDFs\n",
    "        \n",
    "        stitched_images = []\n",
    "        \n",
    "        for group_box in grouped_boxes:\n",
    "            # Scale group box dimensions to pixels\n",
    "            group_x1, group_y1, group_x2, group_y2 = group_box\n",
    "            canvas_width = int((group_x2 - group_x1) * scale)\n",
    "            canvas_height = int((group_y2 - group_y1) * scale)\n",
    "            \n",
    "            # Create a blank canvas for the group\n",
    "            canvas = Image.new('RGBA', (canvas_width, canvas_height), (255, 255, 255, 0))\n",
    "            \n",
    "            for img_bytes, coords in zip(image_data, image_coords):\n",
    "                # Convert image bytes to PIL.Image\n",
    "                img = Image.open(io.BytesIO(img_bytes))\n",
    "                \n",
    "                # Check if this image belongs to the current group\n",
    "                img_x1, img_y1, img_x2, img_y2 = coords\n",
    "                if (\n",
    "                    group_x1 <= img_x1 < group_x2 and group_y1 <= img_y1 < group_y2\n",
    "                    or group_x1 <= img_x2 <= group_x2 and group_y1 <= img_y2 <= group_y2\n",
    "                ):\n",
    "                    # Scale image coordinates to pixels\n",
    "                    paste_x = int((img_x1 - group_x1) * scale)\n",
    "                    paste_y = int((img_y1 - group_y1) * scale)\n",
    "                    img_width = int((img_x2 - img_x1) * scale)\n",
    "                    img_height = int((img_y2 - img_y1) * scale)\n",
    "                    \n",
    "                    # Resize only if necessary, using high-quality resampling\n",
    "                    if img.size != (img_width, img_height):\n",
    "                        img = img.resize((img_width, img_height), resample=Image.Resampling.LANCZOS)\n",
    "                    \n",
    "                    # Paste the image onto the canvas\n",
    "                    canvas.paste(img, (paste_x, paste_y), img if img.mode == 'RGBA' else None)\n",
    "            \n",
    "            stitched_images.append(canvas)\n",
    "    \n",
    "        return stitched_images\n",
    "    \n",
    "    \n",
    "    def _process_pdf_pages(self, pdf_filename:str, images_dir='images'):\n",
    "\n",
    "        file = self.dir_path + pdf_filename\n",
    "        print(\"Processing PDF pages: \"+file)\n",
    "        \n",
    "        dict_mapping_pages = defaultdict(list)\n",
    "\n",
    "        # open the file\n",
    "        pdf_file = fitz.open(file)\n",
    "\n",
    "        # iterate over PDF pages\n",
    "        for page_index in range(len(pdf_file)):\n",
    "\n",
    "            # get the page itself\n",
    "            page = pdf_file.load_page(page_index)  # load the page\n",
    "            image_list = page.get_images(full=True)  # get images on the page\n",
    "\n",
    "            # printing number of images found in this page\n",
    "            if image_list:\n",
    "                print(f\"[+] Found a total of {len(image_list)} images on page {page_index}\")\n",
    "            else:\n",
    "                print(\"[!] No images found on page\", page_index)\n",
    "            \n",
    "            image_data = []\n",
    "            image_coords = []\n",
    "            for image_index, img in enumerate(image_list, start=1):\n",
    "                # get the XREF of the image\n",
    "                xref = img[0]\n",
    "\n",
    "                # extract the image bytes\n",
    "                base_image = pdf_file.extract_image(xref)\n",
    "                image_bytes = base_image[\"image\"]\n",
    "\n",
    "                # get the image extension\n",
    "                image_ext = base_image[\"ext\"]\n",
    "\n",
    "                img_rect = page.get_image_rects(xref)[0]\n",
    "                coords = (img_rect.x0, img_rect.y0, img_rect.x1, img_rect.y1)\n",
    "\n",
    "                # print(page_index+1,image_index,coords)\n",
    "\n",
    "                image_data.append(image_bytes)\n",
    "                image_coords.append(coords)\n",
    "\n",
    "            grouped_boxes = IngestionPipeline.group_connected_rectangles(image_coords, threshold=0)\n",
    "\n",
    "            # print(grouped_boxes)\n",
    "\n",
    "            stitched_images = IngestionPipeline.stitch_grouped_images_with_dpi(image_data, image_coords, grouped_boxes)\n",
    "\n",
    "            # Save or display the stitched images\n",
    "\n",
    "            if not os.path.exists(self.dir_path + images_dir):\n",
    "                os.mkdir(self.dir_path + images_dir)\n",
    "\n",
    "            for i, img in enumerate(stitched_images):\n",
    "                fname =  self.dir_path+images_dir+'/stitched_group_'+str(page_index+1)+'_'+str(i)+'.png'\n",
    "                print('Saving... ', fname)\n",
    "                img.save(fname)\n",
    "                dict_mapping_pages[page_index+1].append(f'stitched_group_{page_index+1}_{i}')\n",
    "            \n",
    "        return dict_mapping_pages\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_image(infilename): # Read image from file system and convert it to numpy array\n",
    "        img = Image.open( infilename )\n",
    "        img.load()\n",
    "        data = np.asarray(img, dtype=\"int32\")\n",
    "        return data\n",
    "\n",
    "    def _extract_paragraphs(self, pdf_filename:str, header_height=140, footer_height=158):\n",
    "        file = self.dir_path + pdf_filename\n",
    "\n",
    "        print(\"Extracting paragraphs: \"+file)\n",
    "        doc = fitz.open(file)\n",
    "\n",
    "        dict_extracted_paragraphs = defaultdict(list)\n",
    "\n",
    "        # header_height = 140 # manually defined\n",
    "        # footer_height = 158\n",
    "\n",
    "        # Iterate over the pages of the PDF\n",
    "        for page_num in tqdm(range(len(doc)), \"pages\"):\n",
    "        # for page_num in range(len(doc)):\n",
    "\n",
    "            # print(\"-\"*10, page_num)\n",
    "\n",
    "            page = doc.load_page(page_num)  # Load the page\n",
    "            \n",
    "            # Convert the page to an image (pixmap)\n",
    "            pix = page.get_pixmap()\n",
    "\n",
    "            # Increase resolution by scaling the page (2x in this case)\n",
    "            matrix = fitz.Matrix(2, 2)  # Scaling by a factor of 2\n",
    "            pix = page.get_pixmap(matrix=matrix)  # Convert page to high-res image\n",
    "\n",
    "            # Convert to Pillow Image\n",
    "            img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "\n",
    "            width, height = img.size\n",
    "            img = img.crop((0, header_height, width, height - footer_height))\n",
    "            \n",
    "            # Apply Tesseract OCR to the image\n",
    "            text = pytesseract.image_to_string(img)\n",
    "\n",
    "            # Print out the extracted text\n",
    "            # print(f\"Text from page {page_num + 1}:\\n{text}\\n\")\n",
    "            dict_extracted_paragraphs[page_num + 1].append(text.replace('\\n',''))\n",
    "            # print('='*10)\n",
    "        \n",
    "        return dict_extracted_paragraphs\n",
    "    \n",
    "    def _ingest_images(self, images_dir):\n",
    "        print(\"Adding images to vector store ...\")\n",
    "        for page,images in self.dict_mapping_pages.items():\n",
    "            for im in images:\n",
    "                image_name = self.dir_path + images_dir + im + '.png' # TODO: Fix name\n",
    "                # print(image_name, os.path.exists(image_name))\n",
    "                if os.path.exists(image_name): \n",
    "                    print(image_name)\n",
    "                    \n",
    "                    # NOTE: si o si hay que agregar el documents porque sino la class Document explota cuando hacemos\n",
    "                    # busquedas porque falta ese field.\n",
    "                    # En algun momento se guardo el base64 de la image, pero no tiene mucho sentido ya que con el uris\n",
    "                    # podemos recuperar la imagen original si es necesario.\n",
    "                    \n",
    "                    self.chroma_collection.add(ids=[im],\n",
    "                                        uris=[image_name],\n",
    "                                        metadatas=[{'page':page,'type':'image'}])\n",
    "    \n",
    "    def _ingest_text(self):\n",
    "        print(\"Adding text to vector store ...\")\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=50)\n",
    "        for page,paragraphs in self.dict_extracted_paragraphs.items():\n",
    "            total_chunks = 0\n",
    "            for i in range(0,len(paragraphs)):\n",
    "                chunked_documents = text_splitter.split_text(paragraphs[i]) \n",
    "                total_chunks += len(chunked_documents)\n",
    "                for j in range(0,len(chunked_documents)):\n",
    "                    self.chroma_collection.add(\n",
    "                        ids=[f'paragraph_{page}_{i}_{j}'],\n",
    "                            documents= [chunked_documents[j]],\n",
    "                            metadatas = [{'page':page,'paragraph':i,'chunk':j,'type':'text'}]\n",
    "                    )\n",
    "            print(\"page:\", page, \"paragraphs:\", len(paragraphs), \"chunks:\", total_chunks)\n",
    "\n",
    "    \n",
    "    def process_pdf(self, pdf_filename:str=None, pickle_filename: str='dicts_images_text.pickle', reload=False, images_dir='images/'):\n",
    "        \n",
    "        if (pdf_filename is not None) and (not reload):\n",
    "            self.dict_mapping_pages = self._process_pdf_pages(pdf_filename)\n",
    "            self.dict_extracted_paragraphs = self._extract_paragraphs(pdf_filename)\n",
    "            with open(self.dir_path + pickle_filename, 'wb') as file:\n",
    "                pickle.dump([self.dict_mapping_pages,self.dict_extracted_paragraphs],file)\n",
    "        else:\n",
    "            self.dict_mapping_pages, self.dict_extracted_paragraphs = pd.read_pickle(self.dir_path + pickle_filename)\n",
    "\n",
    "        # Persist images in vector store\n",
    "        self._ingest_images(images_dir)\n",
    "        # Persist text in vector store\n",
    "        self._ingest_text()\n",
    "\n",
    "    \n",
    "    def get_vector_store_collection(self):\n",
    "        return self.chroma_collection\n",
    "    \n",
    "    def get_vector_store_client(self):\n",
    "        return self.chroma_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating vector store: ./input/chromadb/\n",
      "Recovering existing collection ...\n",
      "elements: 898\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Folder with pdf and extracted images\n",
    "path = \"./input/\"\n",
    "\n",
    "dir_path = path\n",
    "create = False # Set to True if ChromaDB needs to be re-created\n",
    "pipeline = IngestionPipeline(dir_path=dir_path, create=create)\n",
    "# pipeline.process_pdf(pdf_filename='photos.pdf')\n",
    "# pipeline.process_pdf(pdf_filename='historiausina.pdf') # Uncomment to process the PDF with text and images\n",
    "\n",
    "chroma_client = pipeline.get_vector_store_client()\n",
    "chroma_collection = pipeline.get_vector_store_collection()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "from io import BytesIO\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def resize_base64_image(base64_string, size=(128, 128)):\n",
    "    \"\"\"\n",
    "    Resize an image encoded as a Base64 string.\n",
    "\n",
    "    Args:\n",
    "    base64_string (str): Base64 string of the original image.\n",
    "    size (tuple): Desired size of the image as (width, height).\n",
    "\n",
    "    Returns:\n",
    "    str: Base64 string of the resized image.\n",
    "    \"\"\"\n",
    "    # Decode the Base64 string\n",
    "    img_data = base64.b64decode(base64_string)\n",
    "    img = Image.open(io.BytesIO(img_data))\n",
    "\n",
    "    # Resize the image\n",
    "    resized_img = img.resize(size, Image.LANCZOS)\n",
    "\n",
    "    # Save the resized image to a bytes buffer\n",
    "    buffered = io.BytesIO()\n",
    "    resized_img.save(buffered, format=img.format)\n",
    "\n",
    "    # Encode the resized image to Base64\n",
    "    return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def is_base64(s):\n",
    "    \"\"\"Check if a string is Base64 encoded\"\"\"\n",
    "    try:\n",
    "        return base64.b64encode(base64.b64decode(s)) == s.encode()\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "def split_image_text_types(docs):\n",
    "    \"\"\"Split numpy array images and texts\"\"\"\n",
    "    images = []\n",
    "    text = []\n",
    "    for doc in docs:\n",
    "        doc = doc.page_content  # Extract Document contents\n",
    "        if is_base64(doc):\n",
    "            # Resize image to avoid OAI server error\n",
    "            images.append(\n",
    "                resize_base64_image(doc, size=(250, 250))\n",
    "            )  # base64 encoded str\n",
    "        else:\n",
    "            text.append(doc)\n",
    "    return {\"images\": images, \"texts\": text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: This should be part of a RAG class or similar\n",
    "def search(query: str, vector_store, k=3, kind=None, text_threshold=0.5, image_threshold=0.7):\n",
    "    # Note: Processing pipeline must be run first!\n",
    "    if kind is not None:\n",
    "        retrieved = vector_store.query(query_texts=[query], include=['documents', 'metadatas','uris','distances'], n_results=k, where={\"type\": kind})\n",
    "            # print(kind, len(retrieved))\n",
    "    else:\n",
    "        retrieved = vector_store.query(query_texts=[query], include=['documents', 'metadatas','uris','distances'], n_results=k)\n",
    "        # print(len(retrieved))\n",
    "        \n",
    "    # TODO: thresholds are not verified!    \n",
    "    return retrieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ids': [['stitched_group_23_1',\n",
       "   'stitched_group_38_0',\n",
       "   'stitched_group_22_1',\n",
       "   'stitched_group_23_2',\n",
       "   'stitched_group_71_1',\n",
       "   'stitched_group_18_0',\n",
       "   'stitched_group_28_0',\n",
       "   'stitched_group_31_1',\n",
       "   'stitched_group_71_5',\n",
       "   'stitched_group_47_1']],\n",
       " 'embeddings': None,\n",
       " 'documents': [[None, None, None, None, None, None, None, None, None, None]],\n",
       " 'uris': [['./input/images/stitched_group_23_1.png',\n",
       "   './input/images/stitched_group_38_0.png',\n",
       "   './input/images/stitched_group_22_1.png',\n",
       "   './input/images/stitched_group_23_2.png',\n",
       "   './input/images/stitched_group_71_1.png',\n",
       "   './input/images/stitched_group_18_0.png',\n",
       "   './input/images/stitched_group_28_0.png',\n",
       "   './input/images/stitched_group_31_1.png',\n",
       "   './input/images/stitched_group_71_5.png',\n",
       "   './input/images/stitched_group_47_1.png']],\n",
       " 'data': None,\n",
       " 'metadatas': [[{'page': 23, 'type': 'image'},\n",
       "   {'page': 38, 'type': 'image'},\n",
       "   {'page': 22, 'type': 'image'},\n",
       "   {'page': 23, 'type': 'image'},\n",
       "   {'page': 71, 'type': 'image'},\n",
       "   {'page': 18, 'type': 'image'},\n",
       "   {'page': 28, 'type': 'image'},\n",
       "   {'page': 31, 'type': 'image'},\n",
       "   {'page': 71, 'type': 'image'},\n",
       "   {'page': 47, 'type': 'image'}]],\n",
       " 'distances': [[0.6440167427062988,\n",
       "   0.6655499339103699,\n",
       "   0.6981176733970642,\n",
       "   0.7003489136695862,\n",
       "   0.7006263732910156,\n",
       "   0.7014427781105042,\n",
       "   0.7014929056167603,\n",
       "   0.7046815156936646,\n",
       "   0.7051355838775635,\n",
       "   0.7064036130905151]],\n",
       " 'included': [<IncludeEnum.distances: 'distances'>,\n",
       "  <IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.uris: 'uris'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query = \"En qué año se fundó la Usina?\"\n",
    "query = \"Primer edificio de la Usina de Tandil\"\n",
    "results = search(query, chroma_collection, k=10, kind='image')\n",
    "print(len(results))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chroma_collection.name\n",
    "# chroma_client.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_from_client = Chroma( # This is the Langchain wrapper\n",
    "    client=chroma_client,\n",
    "    collection_name=chroma_collection.name,\n",
    "    embedding_function=OpenCLIPEmbeddings(model_name=\"ViT-B-32\", checkpoint=\"laion2b_s34b_b79k\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import Optional\n",
    "# from pydantic import BaseModel\n",
    "# from langchain.chains.query_constructor.ir import (\n",
    "#     Comparator,\n",
    "#     Comparison,\n",
    "#     Operation,\n",
    "#     Operator,\n",
    "#     StructuredQuery,\n",
    "# )\n",
    "# from langchain.retrievers.self_query.chroma import ChromaTranslator\n",
    "\n",
    "\n",
    "# class Search(BaseModel):\n",
    "#     query: str\n",
    "#     kind: Optional[str]\n",
    "\n",
    "# search_query = Search(query=\"type\", kind=\"image\")\n",
    "\n",
    "# def construct_comparisons(query: Search):\n",
    "#     comparisons = []\n",
    "#     if query.kind is not None:\n",
    "#         comparisons.append(\n",
    "#             Comparison(\n",
    "#                 comparator=Comparator.EQ,\n",
    "#                 attribute=\"type\",\n",
    "#                 value=query.kind,\n",
    "#             )\n",
    "#         )\n",
    "#     return comparisons\n",
    "\n",
    "# comparisons = construct_comparisons(search_query)\n",
    "# _filter = Operation(operator=Operator.AND, arguments=comparisons)\n",
    "# filter_for_chroma = ChromaTranslator().visit_operation(_filter)\n",
    "# filter_for_chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make retriever\n",
    "retriever = vector_store_from_client.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"score_threshold\": 0.2, 'k': 10}, # \"filter\": {'type': {'$eq': 'image'}}}\n",
    ")\n",
    "# TODO: Maybe we need a custom retriever for the multimodal collection, interacting directly with ChromaDB for images\n",
    "# https://python.langchain.com/docs/how_to/custom_retriever/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='paragraph_72_0_2', metadata={'chunk': 2, 'page': 72, 'paragraph': 0, 'type': 'text'}, page_content=\"Lo hicimos en un dia,en una caravana. Lo tinico que les pedi a los empleados fue que cada cual levara suspertenencias. Y cuando llegaron a Nigro se encontraron con sus oficinas y un cartelitodel escritorio que le tocaba a cada uno”,'” conté Cabitto.El ultimo acto como presidente de la Usina del Dr. Carlos Nicolini, el 2 de enerode 2008, fue para presidir la inauguracién del edificio con que la empresa dejépara siempre en el pasado el trauma de “las dos usinas”. Con la presidencia enciernes del Ing. Daniel\"),\n",
       " Document(id='paragraph_44_0_3', metadata={'chunk': 3, 'page': 44, 'paragraph': 0, 'type': 'text'}, page_content='van y vuelven a lo largo de esta crénica.Uno de los primeros camiones de la Usina'),\n",
       " Document(id='paragraph_23_0_13', metadata={'chunk': 13, 'page': 23, 'paragraph': 0, 'type': 'text'}, page_content='del barrio de laEstacion contra otros vecinos que habianayudado a los conservadores. De esta ma-nera un camionero y un quimico farma-céutico, ...’que se prestaron incondicio-nalmente a las maniobras fraudulentas delos conservadores, estan purgando en estemomento lo inmoral de su conducta. Todasu clientela la formaban ferroviarios, quede comin acuerdo han decidido no com-prar mas en los referidos negocios, quevivian gracias al favor exclusivo de estosclientes’. Aparentemente, por lo menospara los redactores'),\n",
       " Document(id='paragraph_8_0_0', metadata={'chunk': 0, 'page': 8, 'paragraph': 0, 'type': 'text'}, page_content='Debemos destacar el cardcter singular de aquella gesta pueblerina que lanz6é aTandil, con la creacién de la Usina, a ochenta afios de desarrollo que lo ha llevadoa su actual condicién excepcional entre los pueblos de la provincia.La poca disponibilidad y el alto costo de la energfa eléctrica era, hacia fines de losafios veinte, el mayor factor limitante a la pujanza de los pueblos bonaerenses.Las cooperativas eléctricas, iniciadas en Punta Alta en 1926, fueron una reacciéninteligente y eficaz. La Usina'),\n",
       " Document(id='paragraph_48_0_1', metadata={'chunk': 1, 'page': 48, 'paragraph': 0, 'type': 'text'}, page_content='afuera. Y yo lo cargaba.... Metéla colita para adentro!”, le decia. El mie-do a la corriente muchas veces tiene quever con la ensefianza o con el descono-cimiento. Hay que cometer un error muyextranjero. Metaliirgica Tandil sera de esta manera el tutor de Metan, Tandilfer, Tan-dilmat, Talleres Tandil, Fundalum, Ronicevi, entre tantos otros.”Naturalmente, la vida de Metaltirgica, como industria modelo y formadora de otraspequefias pymes, estard ligada al desarrollo de la Usina hasta fines del siglo'),\n",
       " Document(id='paragraph_61_0_1', metadata={'chunk': 1, 'page': 61, 'paragraph': 0, 'type': 'text'}, page_content=\"pagaderos porparte de la Camara Empresaria a mil dolares por mes, lo cual parece un precio y unplazo por demis accesibles en razén al argumento que Canziani aportaria treintaafios después para entender la sustancia de la operacién alld por 1987: “Nadie de losque participamos en aquella cuestién tomé esto como un negocio en si mismo porque enese momento la Usina era estratégica, pero no generaba rentabilidad. En aquellos dias nohabia un concepto de negocio como tal”.’' Sin embargo, hacia el interior de la\"),\n",
       " Document(id='paragraph_58_0_2', metadata={'chunk': 2, 'page': 58, 'paragraph': 0, 'type': 'text'}, page_content='encuenta que el microcentro era registrado como el corazén del pueblo.'),\n",
       " Document(id='paragraph_50_0_5', metadata={'chunk': 5, 'page': 50, 'paragraph': 0, 'type': 'text'}, page_content='andar el empleado antes. Era poco. Hoy en dia se hacen veinte o treinta. A esascuatro o seis manzanas se les llamaban rutas. El estado del medidor se tomaba mensual deavenida a avenida, es decir de Rivadavia a Buzén y de Avellaneda a Del Valle, era mensual.Y habia lugares que se hacta cada dos meses. Pero habia zonas que no se podian hacer pormanzanas. Yo por ejemplo hacia una ruta que salia de Larrea y Santos Vega, por alld arri-ba. No habia tantas casas como ahora. Hacia del otro lado de Bolivar hasta'),\n",
       " Document(id='paragraph_21_0_5', metadata={'chunk': 5, 'page': 21, 'paragraph': 0, 'type': 'text'}, page_content='plantados y la amplia calle de ida yvuelta a la estacién del ferrocarril también funcionaba como el cordén umbilical de loque fue el primer de barrio de la ciudad: el barrio de la Estacién.Esas dos motivaciones que oscilaban en torno a la epopeya por la Usina devenian de loque el acontecimiento importaba como tal. Uno, la maytiscula dimensién de la obraen s{ misma. Su poderosa envergadura. Dos, el ideario cooperativista con que comen-zaba a edificar los cimientos de semejante proyecto en el corazén de la'),\n",
       " Document(id='paragraph_80_0_4', metadata={'chunk': 4, 'page': 80, 'paragraph': 0, 'type': 'text'}, page_content='los autores.Entrevista con los autores.Entrevista con los autores.Entrevista con los autores.Entrevista con los autores.Entrevista con los autores.Entrevista con los autores.Entrevista con los autores.Entrevista con los autores.Entrevista con los autores.Entrevista con los autores.Entrevista con los autores.Entrevista con los autores.Entrevista con los autores.Titie Vantac “In hambre ca cisicidA an Tandil franta104105106107108109110111El Eco de Tandil, 19-1-02.Entrevista con los autores.Entrevista con los')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"carreta\"\n",
    "retriever.invoke(query) #, metadata={\"type\": 'image'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_func(data_dict):\n",
    "    # Joining the context texts into a single string\n",
    "    formatted_texts = \"\\n\".join(data_dict[\"context\"][\"texts\"])\n",
    "    messages = []\n",
    "\n",
    "    # Adding image(s) to the messages if present\n",
    "    if data_dict[\"context\"][\"images\"]:\n",
    "        image_message = {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{data_dict['context']['images']}\"\n",
    "            },\n",
    "        }\n",
    "        messages.append(image_message)\n",
    "\n",
    "    # Adding the text message for analysis\n",
    "    text_message = {\n",
    "        \"type\": \"text\",\n",
    "        \"text\": (\n",
    "            \"As an expert historian and particularly in Tandil history, your task is to analyze and interpret text and images, \"\n",
    "            \"considering their historical and cultural significance. Provide your response in Spanish. Alongside the images, you will be \"\n",
    "            \"provided with related text to offer context. Both will be retrieved from a vectorstore based \"\n",
    "            \"on user-input keywords. Please use your extensive knowledge and analytical skills to provide a \"\n",
    "            \"comprehensive summary that includes:\\n\"\n",
    "            \"- A detailed description of your answer.\\n\"\n",
    "            \"- The historical and cultural context for the text and images (if any).\\n\"\n",
    "            \"- An interpretation of the image's symbolism and meaning.\\n\"\n",
    "            \"- Connections between the text and images (if any).\\n\\n\"\n",
    "            f\"User-provided keywords: {data_dict['question']}\\n\\n\"\n",
    "            \"Text and / or tables:\\n\"\n",
    "            f\"{formatted_texts}\"\n",
    "        ),\n",
    "    }\n",
    "    messages.append(text_message)\n",
    "\n",
    "    return [HumanMessage(content=messages)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading OPENAI config: /Users/adiazpace/Documents/GitHub/openai-conversational-voice-chatbot/andres.env True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "ENV_PATH = Path('.') / 'andres.env'\n",
    "result = load_dotenv(dotenv_path=ENV_PATH.resolve(), override=True)\n",
    "print(\"Reading OPENAI config:\", ENV_PATH.resolve(), result)\n",
    "\n",
    "# load_dotenv()\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"OPENAI_MODEL_NAME\"] = os.getenv(\"LLM_MODEL\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=os.environ[\"OPENAI_MODEL_NAME\"],\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # api_key=\"...\",  # if you prefer to pass api key in directly instaed of using env vars\n",
    "    # base_url=\"...\",\n",
    "    # organization=\"...\",\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(temperature=0, model=os.environ[\"OPENAI_MODEL_NAME\"], api_key=os.environ[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Amo programmare.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 31, 'total_tokens': 37, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-e059c81a-42f9-4f38-b13a-9ea9c7e2bf28-0', usage_metadata={'input_tokens': 31, 'output_tokens': 6, 'total_tokens': 37, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to Italian. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG pipeline\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": retriever | RunnableLambda(split_image_text_types),\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | RunnableLambda(prompt_func)\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indgenes de la construccién del edificio tinico.que se le da a Usicom aludia en un principio hacia dénde querian orientarse esosnuevos negocios, tal como lo explicé el gerente Mario Cabitto: “Usicom se llamaUsicom porque era una sintesis de ‘Usina- Comunicaciones’, dado que se pensaba haceralgo en el tema vinculado a comunicacién como television, telefonia e internet. Es decircablear con fibra éptica y llegar a la comunidad con esos tres servicios. Es mds iniciamoslos trdmites con la Comision Nacional de\n",
      "de nuestroedificio. La pluma brillante que dejo co-trer en el original los dicterios y piramida-les razonamientos que la venenosa hojitadifundiera, se escudaba entonces en elanénimo, hoy un boletin de ‘La Semana’,que lleva el ndmero 1 como advirtiendoque su aparicion no sera Gnica; por la re-peticion de iguales términos e idénticosrazonamientos, descubre al IGNORADOautor de aquél. Ya le conociamos el nido,pero al hombre le gustaba jugar a las es-condidas. Hoy ya habra llegado a una am-plia inteligencia con\n",
      "El jurado evalia los proyectospresentados para el edificio de calle Nigro.gabinete de gobierno y empezaba a contagiar a sus intimos de las bondades de unslogan que hasta ese momento los tandilenses habian escuchado durante la extensacampafia de ocho meses que realizé el pediatra: la construccién del Tandil Sofiado.La segunda eleccién, intensa pero mucho mds acotada en su masa critica -tantoque apenas votaron 300 personas- ocurrié en noviembre de 2003 y consagréal Ing. Patricio Fernandez como el nuevo\n",
      "esta descripcién del Tandil contempordneo a las visperas delproceso fundacional de la Usina, como asf también a lo que habrd de ocurrir durantesus primeros afios de vida, porque define un clima de época.Entre 1930 y 1940 Tandil recibié dos epifanias tecnoldgicas: la Usina propia y el ac-ceso al agua corriente. Con los afios 30 aparecié claramente “una vida social mds frag-mentada y compleja, menos polar, con una nueva composicién de los sectores populares ycon clases. medias en ascenso, las que se\n",
      "del pueblo de Tandil dela que Juan Nigro fue su indiscutible iniciador y paladin’.”*Oficina central del edificio de 9 de Julio 430.Imagen del hall de planta baja.Imagen del hall planta alta.\n",
      "I y II de su PlantaOperativa siguiendo el mismo disefio arquitecténico que el edificio central de calleNigro. Las obras comprendieron la remodelacién y ampliacién de 426 * de cons-truccién en la ochava de Nigro y Séenz Pefia, donde funcionan las dependencias deLaboratorio; Redes; Guardia y Explotacién del Servicio; Subestaciones y Adminis-trativos de Servicios Complementarios.También se intervino en la playa de acceso y el estacionamiento interno de la PlantaOperativa que deparé una mejor funcionalidad en\n",
      "Per6n por las calles de Tandil. Pero a lahora de construir un consenso, nuevamente -como a lo largo de la historia-, se sintiéde manera contundente el peso de las instituciones y en especial la presién de ciertasempresas de fuerte apego local sobre el poder politico. La Compafiia de Seguros LaTandilense, a través de Juan Canziani y Metaliirgica Tandil, con la figura ya icénicade Santiago Selvetti, son dos ejemplos al respecto. No resulté menor el dato del pre-cio del kilovat en esta historia, porque en los\n",
      "Popular se expresaba que “el edificio, con sus lineas severas eimponentes, se yergue airoso, como un exponente de progreso, al par que pone una notaedilicia en la febril barriada obrera, que es uno de los sélidos puntales de nuestra obra(...) Y mientras los obreros cumplen su tarea, levantando el edificio, colocando postes ytendiendo los cables que transportaran el fluido maravilloso a todos los hogares de Tandil,nosotros —accionistas y pueblo- damos un nuevo y vigoroso impulso a la obra de todos”.El\n",
      "proyecté con unaplanta baja, un primer piso para oficinas y cuatro plantas con la idea de formar unconsorcio con otros vecinos de Tandil destinado a departamentos y oficinas. La ideaera que esta “venta de espacio” lograra un abaratamiento de los costos de las oficinasinherentes a la Usina. La arquitecta Ruth Massera de Castelnuovo fue la autora delproyecto, un edificio de dos plantas destinado a dependencias administrativas.Con la Ilegada de los afios 60, Tandil se aprestaba a una segunda gesta, si\n",
      "un apellido que esta ligado intimamente a Tandil porque en 1964 la familiadoné los terrenos donde fue construida la Terminal de Omnibus). La presién de lavecindad obligé a actuar répido a la nueva comisién, a tal punto que se compraron50 faroles y se le avisé al vecindario que deberian hacerse cargo del costo de los mis-mos. En 1870 se ordené la compra de 90 faroles para velas de sebo. La adquisiciénmiraba el futuro inmediato, pues los faroles tenian un dispositivo previsto para sertransformados a\n",
      "nuevo y vigoroso impulso a la obra de todos”.El dibujo original del edificio que se habfa proyectado comprendia una sala de ma-tasa haa oe i oeDERE PEDECECET ES GPE YCCEY CEOS OEEAEC LOPS eC C SEs CAUSE 4Sala de bombas y refrigeradores de 10 por 8, con altura de 5 metros. Taller de 8 por4 metros, con entrada para camiones, depésitos para piezas de repuestos de 4 por4 metros. Servicios. Dos lavatorios y espacio para guardarropas, tanque de cementode 80 a 100 mil litros con fondo a 12 metros del nivel de la\n",
      "usinaTANDILUSINA POPULAR Y MUNICIPAL DE TANDIL S.E.M.CesCamara Empresaria de TandilLa Camara con la ComunidadaMunicipiodelandilLugar Sofiado\n",
      "en que Tandil estuvo alumbrado al unisonopor la empresa que llegaba y la que no queria irse. La actitud de bloqueo a la Usinapor parte del Municipio fue tan solapada que vale la pena citar algunos parrafos delvespertino Nueva Era: “Las dificultades impuestas por la Municipalidad a la aproba-cin de los planos, la suspension de los trabajos de construccién del edificio de la usina,las reticencias para firmar la constancia de que la Municipalidad participa del consorcioPopular no pueda terminar sus\n",
      "Usina esta vinculada al Tandil bipolar: el prospero y el vulnerado. Es la Usina queinstala sus medidores en un barrio residencial cerrado y con todos los servicios, pero tam-bién es la Usina que llega para darle luz a la tiltima casita que aparece sobre una callede tierra, lejana y mustia, de un lugar remoto y sin nombre, un barrio que fue naciendode la nada, con los nuevos vecinos que eligieron la ciudad para vivir. Es la Usina que secompromete en el desafio con que hoy miramos el futuro: como una\n",
      "el primer piso del mo-derno edificio. Fueron reconocidos el sefior Luis Dell’ Acqua, el ingeniero CarlosBassi, los ingenieros Patricio Fernandez, Esteban Elissondo, el sehor Aldo Guindo, eldoctor Victorino Pugliese, el agrimensor Carlos Nicolini, la sefiora Elida de Levy, elsefior Horacio Canziani, el ingeniero Julio Mufioz, el doctor Ricardo Sudrez Garcia,los contadores Manuel Cagliolo, Angel Etcheto, Juan Boltiansky, Héctor Lavayén,Daniel Alvarez, Ricardo Saracca, Omar Farah, los ingenieros Juan Terfi y\n",
      "con la DEBA, y Jorgelogré refinanciar esas deudas con la Provincia y al mismo tiempo consiguié un cuadrotarifario con que se entré a la convertibilidad de manera muy positiva en Tandil, tantoque a la empresa le dejé buenas utilidades. Otro de sus aciertos fue que refinancié ladeuda que tenta el Municipio con la Usina, que la acordé en ese momento con Pizzor-no, que lo mantuvieron y la Municipalidad cumplié con el plan de pago. Y tambiénlogré un orden administrativo y de gestién en la empresa con Sanmarcos.\n",
      "mds un problema antes que una necesidad. En 1858 Tandil estaba habitada por 86casas de ladrillo y adobe con techo de paja, y 19 casas de comercio, una fonda, unaconfiteria, dos billares, tres panaderias, una barberia, tres zapaterias, dos boterias,una sastreria, dos carpinterias, una herreria, una plateria, un molino de agua, unatahona, cinco hornos de cocer ladrillo y la escuela de varones con 23 inscriptos.El gran farol produjo lo que siempre suele ocurrir en las sociedades pequefias ante lonovedad de lo\n",
      "Municipalidad de Tandi, 2009.Ibid.jAdelante!, periddico de la Usina Popular de Tandil, septiembre de 1934.Luciano Barandarian, Un socialista del interior. Juan Nigro en Tandil1928-1946}. Municipalidad de Tandi, 2009.Ibid.Ibid.Daniel Eduardo Pérez, Los conservadores de Tandil. Blog HistoricusRicado Pasolini, Elias El Hage, Tandil en la Argentina del BicentenarioVida cotidiana y sociedad 1823-2010. Tandil, 2010.Ibid.Ibid.Ibid.Daniel Eduardo Pérez, Historias del Tandil II, Ciddle Editora, 2008.Carlos Marcelo\n",
      "ser la primera usinadel pueblo, en un inmueble de calle Paz 623. Las vecinas mas directas de ese empren-dimiento -que la casi unanimidad social habfa condenado al fracaso y cuyas primeraspruebas habrian de ocurrir en 1896-, fueron las alumnas del Colegio de Hermanas.La revancha se la dio el carnaval, como un episodio si se quiere de ocasién, de furtivafelicidad reivindicatoria. Porque a Prado lo habia derrotado la idiosincrasia de lacomunidad. La negacién sistémica ante la novedad. Y también su falta de\n",
      "la Iglesia, el Municipio, y en un vértice de la plaza mayor el increibleHotel Palace cuya suntuosidad, casi fuera de contexto para la austera tandilidad de-cimonénica, a diez afios de construido todavia seguia derritiendo con su glamorosanovedad a propios y extrafios. A vecinos y veraneantes, puesto que asi se los llamabapor entonces a los turistas. No. Para Nigro el mundo del progreso empezaba en laestacién. Y ubicaba como dato clave de un éxito atin todavia inacabado pero que ha-bia aprendido a sortear\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import HTML, display, Markdown\n",
    "\n",
    "\n",
    "def plt_img_base64(img_base64):\n",
    "    # Create an HTML img tag with the base64 string as the source\n",
    "    image_html = f'<img src=\"data:image/jpeg;base64,{img_base64}\" />'\n",
    "\n",
    "    # Display the image by rendering the HTML\n",
    "    display(HTML(image_html))\n",
    "\n",
    "\n",
    "# query = \"Origen de la Usina y su fundación\"\n",
    "query = \"Primer edificio de la Usina de Tandil\"\n",
    "docs = retriever.invoke(query, k=20)\n",
    "for doc in docs:\n",
    "    if is_base64(doc.page_content):\n",
    "        plt_img_base64(doc.page_content)\n",
    "    else:\n",
    "        print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Análisis del Primer Edificio de la Usina de Tandil\n",
       "\n",
       "#### Descripción Detallada\n",
       "El texto proporcionado ofrece un panorama sobre la construcción del primer edificio de la Usina de Tandil, resaltando su importancia en el desarrollo tecnológico y social de la ciudad durante las décadas de 1930 y 1940. Se menciona que la Usina, inicialmente concebida como un centro de comunicaciones, se convirtió en un símbolo de progreso y modernización para la comunidad. La obra fue diseñada por la arquitecta Ruth Massera de Castelnuovo y se caracterizó por su estructura imponente, que se alza como un exponente del avance tecnológico en un contexto de creciente complejidad social.\n",
       "\n",
       "#### Contexto Histórico y Cultural\n",
       "La construcción de la Usina se sitúa en un período crucial para Tandil, donde la llegada de servicios básicos como la electricidad y el agua corriente transformó la vida cotidiana de sus habitantes. Entre 1930 y 1940, la ciudad experimentó un cambio significativo en su estructura social, con un ascenso de las clases medias y una fragmentación de la vida social. Este contexto se refleja en la necesidad de crear infraestructuras que respondieran a las demandas de una población en crecimiento y en transformación.\n",
       "\n",
       "La Usina no solo representó un avance tecnológico, sino que también se convirtió en un símbolo de la identidad local, uniendo a la comunidad en torno a un proyecto común. La referencia a la \"pluma brillante\" y a la \"febril barriada obrera\" en el texto sugiere un reconocimiento del esfuerzo colectivo y la importancia del trabajo en equipo para lograr el progreso.\n",
       "\n",
       "#### Interpretación de la Simbología de la Imagen\n",
       "Aunque no se han proporcionado imágenes específicas, se puede inferir que las representaciones visuales del edificio de la Usina, como el hall de planta baja y el hall de planta alta, simbolizan la modernidad y el progreso. La arquitectura del edificio, con sus \"líneas severas e imponentes\", puede interpretarse como un reflejo de la seriedad y la determinación de la comunidad de Tandil para avanzar hacia un futuro más próspero.\n",
       "\n",
       "El uso de materiales y el diseño funcional del edificio también pueden ser vistos como una metáfora de la resiliencia de la ciudad, que, a pesar de los desafíos, se esfuerza por construir un entorno que beneficie a todos sus habitantes.\n",
       "\n",
       "#### Conexiones entre el Texto y las Imágenes\n",
       "El texto y las imágenes se complementan al narrar la historia de la Usina como un proyecto que no solo se limita a la construcción física de un edificio, sino que también abarca el desarrollo de una comunidad. La mención de la participación de empresas locales y la presión de instituciones en el proceso de construcción subraya la interconexión entre el desarrollo económico y social de Tandil.\n",
       "\n",
       "Además, el texto destaca la importancia de la participación ciudadana en la toma de decisiones, lo que se refleja en la elección de proyectos y en la construcción de un consenso en torno a la Usina. Esto sugiere que el edificio no solo es un espacio físico, sino un punto de encuentro para la comunidad, donde se forjan lazos y se construye identidad.\n",
       "\n",
       "### Conclusión\n",
       "El primer edificio de la Usina de Tandil es un testimonio del progreso tecnológico y social de la ciudad en un momento clave de su historia. A través de su construcción, se evidencia la transformación de la vida cotidiana de los tandilenses y la importancia de la colaboración comunitaria. Las imágenes del edificio, junto con el texto, ofrecen una rica narrativa que invita a reflexionar sobre el papel de la infraestructura en la construcción de la identidad y el desarrollo de una comunidad."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = chain.invoke(query)\n",
    "display(Markdown(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
